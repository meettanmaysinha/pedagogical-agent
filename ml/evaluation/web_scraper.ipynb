{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SCHOOL\\WSS\\pedagogical-agent\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import fitz\n",
    "from transformers import GPT2TokenizerFast\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer_gpt = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer_gpt.encode(text))\n",
    "\n",
    "# Step 1: Extract text from webpage\n",
    "def read_webpage(url: str, class_type: str, class_name: str) -> str:\n",
    "    \"\"\"Extract text from a web page and return it as a single string.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch page: {url}\")\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    main_content = soup.find(class_type, class_=class_name)\n",
    "\n",
    "    if main_content:\n",
    "        return main_content.get_text(separator=\"\\n\", strip=True)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def read_pdf(file_path: str) -> str:\n",
    "    \"\"\"Extract text from a PDF file and return it as a single string.\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with fitz.open(file_path) as pdf:\n",
    "            for page_num in range(len(pdf)):\n",
    "                page = pdf.load_page(page_num)\n",
    "                text += page.get_text(\"text\")  # Extract text from each page\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error reading {file_path}: {e}\")\n",
    "        return \"\"\n",
    "    \n",
    "    return text\n",
    "\n",
    "def process_webpage(url: str, page_name: str, class_type: str, class_name: str):\n",
    "    \"\"\"Process webpage text and split it into chunks using RecursiveCharacterTextSplitter.\"\"\"\n",
    "    \n",
    "    # Extract text from webpage\n",
    "    text = read_webpage(url, class_type, class_name)\n",
    "    \n",
    "    if not text:\n",
    "        print(f\"No content extracted from {url}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=256,  # Size of chunks (in tokens)\n",
    "        chunk_overlap=24,  # Tokens overlap between chunks\n",
    "        length_function=count_tokens,  # Function to count tokens in each chunk\n",
    "    )\n",
    "\n",
    "    # Split text into chunks\n",
    "    chunks = text_splitter.create_documents([text])\n",
    "    chunks = [chunk.page_content for chunk in chunks]\n",
    "\n",
    "    print(f\"Processed {page_name}: {len(chunks)} chunks\")\n",
    "\n",
    "    # Store processed data in dictionary\n",
    "    processed_web_data[page_name] = chunks\n",
    "\n",
    "def process_pdf(file_path: str, pdf_name: str):\n",
    "    \"\"\"Process PDF text and split it into chunks using RecursiveCharacterTextSplitter.\"\"\"\n",
    "    \n",
    "    # Extract text from PDF\n",
    "    text = read_pdf(file_path)\n",
    "    \n",
    "    if not text:\n",
    "        print(f\"No content extracted from {file_path}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=256,  # Size of chunks (in tokens)\n",
    "        chunk_overlap=24,  # Tokens overlap between chunks\n",
    "        length_function=count_tokens,  # Function to count tokens in each chunk\n",
    "    )\n",
    "\n",
    "    # Split text into chunks\n",
    "    chunks = text_splitter.create_documents([text])\n",
    "    chunks = [chunk.page_content for chunk in chunks]\n",
    "\n",
    "    print(f\"Processed {pdf_name}: {len(chunks)} chunks\")\n",
    "\n",
    "    # Store processed data in dictionary\n",
    "    processed_pdf_data[pdf_name] = chunks\n",
    "\n",
    "# Dictionary to store processed web data\n",
    "processed_web_data = {}\n",
    "processed_pdf_data = {}\n",
    "\n",
    "# Example usage\n",
    "# process_pdf(\"docs/sample.pdf\", \"sample_pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1818 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed numpy_cheatsheet: 29 chunks\n"
     ]
    }
   ],
   "source": [
    "url_dict = {\n",
    "    \"https://ipgp.github.io/scientific_python_cheat_sheet/?utm_content=buffer7d821&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer#numpy-import-numpy-as-np\": [\"numpy_cheatsheet\", \"section\", \"main-content\"]\n",
    "}\n",
    "for url, (page_name, class_type, class_name) in url_dict.items():\n",
    "    process_webpage(url, page_name, class_type, class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'numpy_cheatsheet': [\"Scientific Python Cheatsheet\\nScientific Python Cheatsheet\\nPure Python\\nTypes\\nLists\\nDictionaries\\nSets\\nStrings\\nOperators\\nControl Flow\\nFunctions, Classes, Generators, Decorators\\nIPython\\nconsole\\ndebugger\\ncommand line\\nNumPy\\narray initialization\\nindexing\\narray properties and operations\\nboolean arrays\\nelementwise operations and math functions\\ninner/ outer products\\nlinear algebra/ matrix math\\nreading/ writing files\\ninterpolation, integration, optimization\\nfft\\nrounding\\nrandom variables\\nMatplotlib\\nfigures and axes\\nfigures and axes properties\\nplotting routines\\nScipy\\ninterpolation\\nlinear algebra\\nintegration\\nPandas\\ndata structures\\nDataFrame\\nPure Python\\nTypes\\na =\\n2\\n# integer\\nb =\\n5.0\\n# float\\nc =\\n8.3e5\\n# exponential\\nd =\\n1.5\\n+\\n0.5j\\n# complex\\ne =\\n4\\n>\\n5\\n# boolean\\nf =\\n'word'\\n# string\\nLists\\na = [\\n'red'\\n,\\n'blue'\\n,\", \"# string\\nLists\\na = [\\n'red'\\n,\\n'blue'\\n,\\n'green'\\n]\\n# manually initialization\\nb =\\nlist\\n(\\nrange\\n(\\n5\\n))\\n# initialize from iteratable\\nc = [nu**\\n2\\nfor\\nnu in b]\\n# list comprehension\\nd = [nu**\\n2\\nfor\\nnu in b\\nif\\nnu <\\n3\\n]\\n# conditioned list comprehension\\ne = c[\\n0\\n]\\n# access element\\nf = c[\\n1\\n:\\n2\\n]\\n# access a slice of the list\\ng = c[-\\n1\\n]\\n# access last element\\nh = [\\n're'\\n,\\n'bl'\\n] + [\\n'gr'\\n]\\n# list concatenation\\ni = [\\n're'\\n] *\\n5\\n# repeat a list\\n[\\n're'\\n,\\n'bl'\\n].index(\\n're'\\n)\\n# returns index of 're'\\na.append(\\n'yellow'\\n)\\n# add new element to end of list\\na.extend(b)\", \"'yellow'\\n)\\n# add new element to end of list\\na.extend(b)\\n# add elements from list `b` to end of list `a`\\na.insert(\\n1\\n,\\n'yellow'\\n)\\n# insert element in specified position\\n're'\\nin [\\n're'\\n,\\n'bl'\\n]\\n# true if 're' in list\\n'fi'\\nnot in [\\n're'\\n,\\n'bl'\\n]\\n# true if 'fi' not in list\\nsorted\\n([\\n3\\n,\\n2\\n,\\n1\\n])\\n# returns sorted list\\na.pop(\\n2\\n)\\n# remove and return item at index (default last)\\nDictionaries\\na = {\\n'red'\\n:\\n'rouge'\\n,\\n'blue'\\n:\\n'bleu'\\n}\\n# dictionary\\nb = a[\\n'red'\\n]\\n# translate item\\n'red'\\nin a\\n# true if dictionary a contains key 'red'\\nc = [value\\nfor\\nkey, value in a.items()]\\n# loop through contents\", \"c = [value\\nfor\\nkey, value in a.items()]\\n# loop through contents\\nd = a.get(\\n'yellow'\\n,\\n'no translation found'\\n)\\n# return default\\na.setdefault(\\n'extra'\\n, []).append(\\n'cyan'\\n)\\n# init key with default\\na.update({\\n'green'\\n:\\n'vert'\\n,\\n'brown'\\n:\\n'brun'\\n})\\n# update dictionary by data from another one\\na.keys()\\n# get list of keys\\na.values()\\n# get list of values\\na.items()\\n# get list of key-value pairs\\ndel\\na[\\n'red'\\n]\\n# delete key and associated with it value\\na.pop(\\n'blue'\\n)\\n# remove specified key and return the corresponding value\\nSets\\na = {\\n1\\n,\\n2\\n,\\n3\\n}\\n# initialize manually\\nb =\\nset\\n(\\nrange\\n(\\n5\\n))\\n# initialize from iteratable\\na.add(\\n13\\n)\\n# add new element to set\", '))\\n# initialize from iteratable\\na.add(\\n13\\n)\\n# add new element to set\\na.discard(\\n13\\n)\\n# discard element from set\\na.update([\\n21\\n,\\n22\\n,\\n23\\n])\\n# update set with elements from iterable\\na.pop()\\n# remove and return an arbitrary set element\\n2\\nin {\\n1\\n,\\n2\\n,\\n3\\n}\\n# true if 2 in set\\n5\\nnot in {\\n1\\n,\\n2\\n,\\n3\\n}\\n# true if 5 not in set\\na.issubset(b)\\n# test whether every element in a is in b\\na <= b\\n# issubset in operator form\\na.issuperset(b)\\n# test whether every element in b is in a\\na >= b\\n# issuperset in operator form\\na.intersection(b)\\n# return the intersection of two sets as a new set\\na.difference(b)\\n# return the difference of two or more sets as a new set\\na - b\\n# difference in operator form', \"# return the difference of two or more sets as a new set\\na - b\\n# difference in operator form\\na.symmetric_difference(b)\\n# return the symmetric difference of two sets as a new set\\na.union(b)\\n# return the union of sets as a new set\\nc =\\nfrozenset\\n()\\n# the same as set but immutable\\nStrings\\na =\\n'red'\\n# assignment\\nchar = a[\\n2\\n]\\n# access individual characters\\n'red '\\n+\\n'blue'\\n# string concatenation\\n'1, 2, three'\\n.split(\\n','\\n)\\n# split string into list\\n'.'\\n.join([\\n'1'\\n,\\n'2'\\n,\\n'three'\\n])\\n# concatenate list into string\\nOperators\\na =\\n2\\n# assignment\\na +=\\n1\\n(*=, /=)\\n# change and assign\\n3\\n+\\n2\\n# addition\\n3\\n/\\n2\\n# integer (python2) or float (python3) division\\n3\\n//\\n2\\n# integer division\\n3\\n*\", \"3\\n//\\n2\\n# integer division\\n3\\n*\\n2\\n# multiplication\\n3\\n**\\n2\\n# exponent\\n3\\n%\\n2\\n# remainder\\nabs\\n(a)\\n# absolute value\\n1\\n==\\n1\\n# equal\\n2\\n>\\n1\\n# larger\\n2\\n<\\n1\\n# smaller\\n1\\n!=\\n2\\n# not equal\\n1\\n!=\\n2\\nand\\n2\\n<\\n3\\n# logical AND\\n1\\n!=\\n2\\nor\\n2\\n<\\n3\\n# logical OR\\nnot\\n1\\n==\\n2\\n# logical NOT\\n'a'\\nin b\\n# test if a is in b\\na is b\\n# test if objects point to the same memory (id)\\nControl Flow\\n# if/elif/else\\na, b =\\n1\\n,\\n2\\nif\\na + b ==\\n3\\n:\\nprint\\n(\\n'True'\\n)\\nelif\\na + b ==\\n1\\n:\\nprint\\n(\\n'False'\\n)\\nelse\\n:\\nprint\\n(\\n'?'\\n)\\n# for\\na = [\\n'red'\", \"else\\n:\\nprint\\n(\\n'?'\\n)\\n# for\\na = [\\n'red'\\n,\\n'blue'\\n,\\n'green'\\n]\\nfor\\ncolor in a:\\nprint\\n(color)\\n# while\\nnumber =\\n1\\nwhile\\nnumber <\\n10\\n:\\nprint\\n(number)\\n    number +=\\n1\\n# break\\nnumber =\\n1\\nwhile\\nTrue\\n:\\nprint\\n(number)\\n    number +=\\n1\\nif\\nnumber >\\n10\\n:\\nbreak\\n# continue\\nfor\\ni in\\nrange\\n(\\n20\\n):\\nif\\ni %\\n2\\n==\\n0\\n:\\ncontinue\\nprint\\n(i)\\nFunctions, Classes, Generators, Decorators\\n# Function groups code statements and possibly\\n# returns a derived value\\ndef\\nmyfunc(a1, a2):\\nreturn\\na1 + a2\", 'x = myfunc(a1, a2)\\n# Class groups attributes (data)\\n# and associated methods (functions)\\nclass\\nPoint(\\nobject\\n):\\ndef\\n__init__\\n(\\nself\\n, x):\\nself\\n.x = x\\ndef\\n__call__\\n(\\nself\\n):\\nprint\\n(\\nself\\n.x)', 'x = Point(\\n3\\n)\\n# Generator iterates without\\n# creating all values at once\\ndef\\nfirstn(n):\\n    num =\\n0\\nwhile\\nnum < n:\\nyield\\nnum\\n        num +=\\n1\\nx = [i\\nfor\\ni in firstn(\\n10\\n)]\\n# Decorator can be used to modify\\n# the behaviour of a function\\nclass\\nmyDecorator(\\nobject\\n):\\ndef\\n__init__\\n(\\nself\\n, f):\\nself\\n.f = f\\ndef\\n__call__\\n(\\nself\\n):\\nprint\\n(\\n\"call\"\\n)\\nself\\n.f()\\n@myDecorator\\ndef\\nmy_funct():\\nprint\\n(\\n\\'func\\'\\n)\\n\\nmy_funct()\\nIPython\\nconsole\\n<\\nobject\\n>?\\n# Information about the object\\n<\\nobject\\n>.<TAB>\\n# tab completion\\n# run scripts / profile / debug\\n%run myscript.py', '%timeit\\nrange\\n(\\n1000\\n)\\n# measure runtime of statement\\n%run -t  myscript.py\\n# measure script execution time\\n%prun <statement>\\n# run statement with profiler\\n%prun -s <key> <statement>\\n# sort by key, e.g. \"cumulative\" or \"calls\"\\n%run -p  myfile.py\\n# profile script\\n%run -d myscript.py\\n# run script in debug mode\\n%debug\\n# jumps to the debugger after an exception\\n%pdb\\n# run debugger automatically on exception\\n# examine history\\n%history\\n%history ~\\n1\\n/\\n1-5\\n# lines 1-5 of last session\\n# run shell commands\\n!make\\n# prefix command with \"!\"\\n# clean namespace\\n%reset\\n# run code from clipboard\\n%paste\\ndebugger\\nn\\n# execute next line\\nb\\n42\\n# set breakpoint in the main file at line 42\\nb myfile.py:\\n42\\n# set breakpoint in \\'myfile.py\\' at line 42\\nc\\n# continue execution\\nl', \"# set breakpoint in 'myfile.py' at line 42\\nc\\n# continue execution\\nl\\n# show current position in the code\\np data\\n# print the 'data' variable\\npp data\\n# pretty print the 'data' variable\\ns\\n# step into subroutine\\na\\n# print arguments that a function received\\npp\\nlocals\\n()\\n# show all variables in local scope\\npp\\nglobals\\n()\\n# show all variables in global scope\\ncommand line\\nipython --pdb -- myscript.py argument1 --option1\\n# debug after exception\\nipython -i -- myscript.py argument1 --option1\\n# console after finish\\nNumPy (\\nimport numpy as np\\n)\\narray initialization\\nnp.array([\\n2\\n,\\n3\\n,\\n4\\n])\\n# direct initialization\\nnp.empty(\\n20\\n, dtype=np.float32)\\n# single precision array of size 20\\nnp.zeros(\\n200\\n)\\n# initialize 200 zeros\\nnp.ones((\\n3\\n,\\n3\\n), dtype=np.int32)\\n# 3 x 3 integer matrix with ones\", ',\\n3\\n), dtype=np.int32)\\n# 3 x 3 integer matrix with ones\\nnp.eye(\\n200\\n)\\n# ones on the diagonal\\nnp.zeros_like(a)\\n# array with zeros and the shape of a\\nnp.linspace(\\n0\\n.,\\n10\\n.,\\n100\\n)\\n# 100 points from 0 to 10\\nnp.arange(\\n0\\n,\\n100\\n,\\n2\\n)\\n# points from 0 to <100 with step 2\\nnp.logspace(-\\n5\\n,\\n2\\n,\\n100\\n)\\n# 100 log-spaced from 1e-5 -> 1e2\\nnp.copy(a)\\n# copy array to new memory\\nindexing\\na = np.arange(\\n100\\n)\\n# initialization with 0 - 99\\na[:\\n3\\n] =\\n0\\n# set the first three indices to zero\\na[\\n2\\n:\\n5\\n] =\\n1\\n# set indices 2-4 to 1\\na[:-\\n3\\n] =\\n2\\n# set all but last three elements to 2', 'a[:-\\n3\\n] =\\n2\\n# set all but last three elements to 2\\na[start:stop:step]\\n# general form of indexing/slicing\\na[\\nNone\\n, :]\\n# transform to column vector\\na[[\\n1\\n,\\n1\\n,\\n3\\n,\\n8\\n]]\\n# return array with values of the indices\\na = a.reshape(\\n10\\n,\\n10\\n)\\n# transform to 10 x 10 matrix\\na.T\\n# return transposed view\\nb = np.transpose(a, (\\n1\\n,\\n0\\n))\\n# transpose array to new axis order\\na[a <\\n2\\n]\\n# values with elementwise condition\\narray properties and operations\\na.shape\\n# a tuple with the lengths of each axis\\nlen\\n(a)\\n# length of axis 0\\na.ndim\\n# number of dimensions (axes)\\na.sort(axis=\\n1\\n)\\n# sort array along axis\\na.flatten()\\n# collapse array to one dimension\\na.conj()\\n# return complex conjugate', '# collapse array to one dimension\\na.conj()\\n# return complex conjugate\\na.astype(np.int16)\\n# cast to integer\\na.tolist()\\n# convert (possibly multidimensional) array to list\\nnp.argmax(a, axis=\\n1\\n)\\n# return index of maximum along a given axis\\nnp.cumsum(a)\\n# return cumulative sum\\nnp.\\nany\\n(a)\\n# True if any element is True\\nnp.\\nall\\n(a)\\n# True if all elements are True\\nnp.argsort(a, axis=\\n1\\n)\\n# return sorted index array along axis\\nnp.where(cond)\\n# return indices where cond is True\\nnp.where(cond, x, y)\\n# return elements from x or y depending on cond\\nboolean arrays\\na <\\n2\\n# returns array with boolean values\\n(a <\\n2\\n) & (b >\\n10\\n)\\n# elementwise logical and\\n(a <\\n2\\n) | (b >\\n10\\n)\\n# elementwise logical or\\n~a\\n# invert boolean array', '10\\n)\\n# elementwise logical or\\n~a\\n# invert boolean array\\nelementwise operations and math functions\\na *\\n5\\n# multiplication with scalar\\na +\\n5\\n# addition with scalar\\na + b\\n# addition with array b\\na / b\\n# division with b (np.NaN for division by zero)\\nnp.exp(a)\\n# exponential (complex and real)\\nnp.power(a, b)\\n# a to the power b\\nnp.sin(a)\\n# sine\\nnp.cos(a)\\n# cosine\\nnp.arctan2(a, b)\\n# arctan(a/b)\\nnp.arcsin(a)\\n# arcsin\\nnp.radians(a)\\n# degrees to radians\\nnp.degrees(a)\\n# radians to degrees\\nnp.var(a)\\n# variance of array\\nnp.std(a, axis=\\n1\\n)\\n# standard deviation\\ninner/ outer products\\nnp.dot(a, b)\\n# inner product: a_mi b_in\\nnp.einsum(', \"# inner product: a_mi b_in\\nnp.einsum(\\n'ij,kj->ik'\\n, a, b)\\n# einstein summation convention\\nnp.\\nsum\\n(a, axis=\\n1\\n)\\n# sum over axis 1\\nnp.\\nabs\\n(a)\\n# return absolute values\\na[\\nNone\\n, :] + b[:,\\nNone\\n]\\n# outer sum\\na[\\nNone\\n, :] * b[:,\\nNone\\n]\\n# outer product\\nnp.outer(a, b)\\n# outer product\\nnp.\\nsum\\n(a * a.T)\\n# matrix norm\\nlinear algebra/ matrix math\\nevals, evecs = np.linalg.eig(a)\\n# Find eigenvalues and eigenvectors\\nevals, evecs = np.linalg.eigh(a)\\n# np.linalg.eig for hermitian matrix\\nreading/ writing files\\nnp.loadtxt(fname/fobject, skiprows=\\n2\\n, delimiter=\\n','\\n)\\n# ascii data from file\", \"2\\n, delimiter=\\n','\\n)\\n# ascii data from file\\nnp.savetxt(fname/fobject, array, fmt=\\n'\\n%.5f\\n'\\n)\\n# write ascii data\\nnp.fromfile(fname/fobject, dtype=np.float32, count=\\n5\\n)\\n# binary data from file\\nnp.tofile(fname/fobject)\\n# write (C) binary data\\nnp.save(fname/fobject, array)\\n# save as numpy binary (.npy)\\nnp.load(fname/fobject, mmap_mode=\\n'c'\\n)\\n# load .npy file (memory mapped)\\ninterpolation, integration, optimization\\nnp.trapz(a, x=x, axis=\\n1\\n)\\n# integrate along axis 1\\nnp.interp(x, xp, yp)\\n# interpolate function xp, yp at points x\\nnp.linalg.lstsq(a, b)\\n# solve a x = b in least square sense\\nfft\", '# solve a x = b in least square sense\\nfft\\nnp.fft.fft(a)\\n# complex fourier transform of a\\nf = np.fft.fftfreq(\\nlen\\n(a))\\n# fft frequencies\\nnp.fft.fftshift(f)\\n# shifts zero frequency to the middle\\nnp.fft.rfft(a)\\n# real fourier transform of a\\nnp.fft.rfftfreq(\\nlen\\n(a))\\n# real fft frequencies\\nrounding\\nnp.ceil(a)\\n# rounds to nearest upper int\\nnp.floor(a)\\n# rounds to nearest lower int\\nnp.\\nround\\n(a)\\n# rounds to neares int\\nrandom variables\\nfrom\\nnp.random\\nimport\\nnormal, seed, rand, uniform, randint\\nnormal(loc=\\n0\\n, scale=\\n2\\n, size=\\n100\\n)\\n# 100 normal distributed\\nseed(\\n23032\\n)\\n# resets the seed value\\nrand(\\n200\\n)\\n# 200 random numbers in [0, 1)\\nuniform(\\n1', \"rand(\\n200\\n)\\n# 200 random numbers in [0, 1)\\nuniform(\\n1\\n,\\n30\\n,\\n200\\n)\\n# 200 random numbers in [1, 30)\\nrandint(\\n1\\n,\\n16\\n,\\n300\\n)\\n# 300 random integers in [1, 16)\\nMatplotlib (\\nimport matplotlib.pyplot as plt\\n)\\nfigures and axes\\nfig = plt.figure(figsize=(\\n5\\n,\\n2\\n))\\n# initialize figure\\nfig.savefig(\\n'out.png'\\n)\\n# save png image\\nfig, axes = plt.subplots(\\n5\\n,\\n2\\n, figsize=(\\n5\\n,\\n5\\n))\\n# fig and 5 x 2 nparray of axes\\nax = fig.add_subplot(\\n3\\n,\\n2\\n,\\n2\\n)\\n# add second subplot in a 3 x 2 grid\\nax = plt.subplot2grid((\\n2\\n,\\n2\\n), (\\n0\\n,\\n0\\n), colspan=\\n2\\n)\", \"2\\n,\\n2\\n), (\\n0\\n,\\n0\\n), colspan=\\n2\\n)\\n# multi column/row axis\\nax = fig.add_axes([left, bottom, width, height])\\n# add custom axis\\nfigures and axes properties\\nfig.suptitle(\\n'title'\\n)\\n# big figure title\\nfig.subplots_adjust(bottom=\\n0.1\\n, right=\\n0.8\\n, top=\\n0.9\\n, wspace=\\n0.2\\n,\\n                    hspace=\\n0.5\\n)\\n# adjust subplot positions\\nfig.tight_layout(pad=\\n0.1\\n, h_pad=\\n0.5\\n, w_pad=\\n0.5\\n,\\n                 rect=\\nNone\\n)\\n# adjust subplots to fit into fig\\nax.set_xlabel(\\n'xbla'\\n)\\n# set xlabel\\nax.set_ylabel(\", \"'xbla'\\n)\\n# set xlabel\\nax.set_ylabel(\\n'ybla'\\n)\\n# set ylabel\\nax.set_xlim(\\n1\\n,\\n2\\n)\\n# sets x limits\\nax.set_ylim(\\n3\\n,\\n4\\n)\\n# sets y limits\\nax.set_title(\\n'blabla'\\n)\\n# sets the axis title\\nax.\\nset\\n(xlabel=\\n'bla'\\n)\\n# set multiple parameters at once\\nax.legend(loc=\\n'upper center'\\n)\\n# activate legend\\nax.grid(\\nTrue\\n, which=\\n'both'\\n)\\n# activate grid\\nbbox = ax.get_position()\\n# returns the axes bounding box\\nbbox.x0 + bbox.width\\n# bounding box parameters\\nplotting routines\\nax.plot(x,y,\\n'-o'\\n, c=\\n'red'\\n, lw=\\n2\\n, label=\\n'bla'\\n)\\n# plots a line\\nax.scatter(x,y, s=\", \"'bla'\\n)\\n# plots a line\\nax.scatter(x,y, s=\\n20\\n, c=color)\\n# scatter plot\\nax.pcolormesh(xx, yy, zz, shading=\\n'gouraud'\\n)\\n# fast colormesh\\nax.colormesh(xx, yy, zz, norm=norm)\\n# slower colormesh\\nax.contour(xx, yy, zz, cmap=\\n'jet'\\n)\\n# contour lines\\nax.contourf(xx, yy, zz, vmin=\\n2\\n, vmax=\\n4\\n)\\n# filled contours\\nn, bins, patch = ax.hist(x,\\n50\\n)\\n# histogram\\nax.imshow(matrix, origin=\\n'lower'\\n,\\n          extent=(x1, x2, y1, y2))\\n# show image\\nax.specgram(y, FS=\\n0.1\\n, noverlap=\\n128\\n,\", \"ax.specgram(y, FS=\\n0.1\\n, noverlap=\\n128\\n,\\n            scale=\\n'linear'\\n)\\n# plot a spectrogram\\nax.text(x, y, string, fontsize=\\n12\\n, color=\\n'm'\\n)\\n# write text\\nScipy (\\nimport scipy as sci\\n)\\ninterpolation\\n# interpolate data at index positions:\\nfrom\\nscipy.ndimage\\nimport\\nmap_coordinates\\npts_new = map_coordinates(data, float_indices, order=\\n3\\n)\\n# simple 1d interpolator with axis argument:\\nfrom\\nscipy.interpolate\\nimport\\ninterp1d\\ninterpolator = interp1d(x, y, axis=\\n2\\n, fill_value=\\n0\\n., bounds_error=\\nFalse\\n)\\ny_new = interpolator(x_new)\\nIntegration\\nfrom\\nscipy.integrate\\nimport\\nquad\\n# definite integral of python\", 'Integration\\nfrom\\nscipy.integrate\\nimport\\nquad\\n# definite integral of python\\nvalue = quad(func, low_lim, up_lim)\\n# function/method\\nlinear algebra\\nfrom\\nscipy\\nimport\\nlinalg\\nevals, evecs = linalg.eig(a)\\n# Find eigenvalues and eigenvectors\\nevals, evecs = linalg.eigh(a)\\n# linalg.eig for hermitian matrix\\nb = linalg.expm(a)\\n# Matrix exponential\\nc = linalg.logm(a)\\n# Matrix logarithm\\nPandas (\\nimport pandas as pd\\n)\\nData structures\\ns = pd.Series(np.random.rand(\\n1000\\n), index=\\nrange\\n(\\n1000\\n))\\n# series\\nindex = pd.date_range(\\n\"13/06/2016\"\\n, periods=\\n1000\\n)\\n# time index\\ndf = pd.DataFrame(np.zeros((\\n1000\\n,\\n3\\n)), index=index,', '1000\\n,\\n3\\n)), index=index,\\n                    columns=[\\n\"A\"\\n,\\n\"B\"\\n,\\n\"C\"\\n])\\n# DataFrame\\nDataFrame\\ndf = pd.read_csv(\\n\"filename.csv\"\\n)\\n# read and load CSV file in a DataFrame\\nraw = df.values\\n# get raw data out of DataFrame object\\ncols = df.columns\\n# get list of columns headers\\ndf.dtypes\\n# get data types of all columns\\ndf.head(\\n5\\n)\\n# get first 5 rows\\ndf.describe()\\n# get basic statisitics for all columns\\ndf.index\\n# get index column range\\n#column slicin\\n# (.loc[] and .ix[] are inclusive of the range of values selected)\\ndf.col_name\\n# select column values as a series by column name (not optimized)\\ndf[[\\n\\'col_name\\'\\n]]\\n# select column values as a dataframe by column name (not optimized)\\ndf.loc[:,', \"]]\\n# select column values as a dataframe by column name (not optimized)\\ndf.loc[:,\\n'col_name'\\n]\\n# select column values as a series by column name\\ndf.loc[:, [\\n'col_name'\\n]]\\n# select column values as a dataframe by column name\\ndf.iloc[:,\\n0\\n]\\n# select by column index\\ndf.iloc[:, [\\n0\\n]]\\n# select by column index, but as a dataframe\\ndf.ix[:,\\n'col_name'\\n]\\n# hybrid approach with column name\\ndf.ix[:,\\n0\\n]\\n# hybrid approach with column index\\n# row slicin\\nprint\\n(df[:\\n2\\n])\\n# print first 2 rows of the dataframe\\ndf.iloc[\\n0\\n:\\n2\\n, :]\\n# select first 2 rows of the dataframe\\ndf.loc[\\n0\\n:\\n2\\n,\\n'col_name'\\n]\\n# select first 3 rows of the dataframe\\ndf.loc[\\n0\\n:\\n2\\n, [\\n'col_name1'\\n,\", \"df.loc[\\n0\\n:\\n2\\n, [\\n'col_name1'\\n,\\n'col_name3'\\n,\\n'col_name6'\\n]]\\n# select first 3 rows of the 3 different columns\\ndf.iloc[\\n0\\n:\\n2\\n,\\n0\\n:\\n2\\n]\\n# select fisrt 3 rows and first 3 columns\\n# Again, .loc[] and .ix[] are inclusive\\n# Dicin\\ndf[ df.col_name <\\n7\\n]\\n# select all rows where col_name < 7\\ndf[ (df.col_name1 <\\n7\\n) & (df.col_name2 ==\\n0\\n) ]\\n# combine multiple boolean indexing conditionals using bit-wise logical operators.\\n# Regular Python boolean operators (and, or) cannot be used here.\\n# Be sure to encapsulate each conditional in parenthesis to make this work.\\ndf[df.recency <\\n7\\n] = -\\n100\\n# writing to slice\\nScientific python cheat sheet\\nis maintained by\\nIPGP\\n.\\nThis page was generated by\\nGitHub Pages\\nusing the\", 'is maintained by\\nIPGP\\n.\\nThis page was generated by\\nGitHub Pages\\nusing the\\nCayman theme\\nby\\nJason Long\\n.']}\n"
     ]
    }
   ],
   "source": [
    "print(processed_web_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1494 Q&A pairs into 11917 chunks\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_csv(file_path: str):\n",
    "    \"\"\"Read CSV file and extract relevant columns.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure necessary columns exist\n",
    "    required_columns = {\"QuestionTitle\", \"QuestionBody\", \"AnswerBody\"}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        raise ValueError(f\"CSV file must contain columns: {required_columns}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def process_csv(file_path: str):\n",
    "    \"\"\"Process CSV data and split it into text chunks.\"\"\"\n",
    "    df = read_csv(file_path)\n",
    "\n",
    "    # Initialize text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=256,  # Size of chunks (in tokens)\n",
    "        chunk_overlap=24,  # Overlap between chunks\n",
    "        length_function=count_tokens,\n",
    "    )\n",
    "\n",
    "    all_chunks = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # Combine Question and Answer\n",
    "        combined_text = f\"Title: {row['QuestionTitle']}\\n\\nQuestion: {row['QuestionBody']}\\n\\nAnswer: {row['AnswerBody']}\"\n",
    "\n",
    "        # Split the text into chunks\n",
    "        chunks = text_splitter.create_documents([combined_text])\n",
    "        chunks = [chunk.page_content for chunk in chunks]\n",
    "        \n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "    print(f\"Processed {len(df)} Q&A pairs into {len(all_chunks)} chunks\")\n",
    "\n",
    "    # Embed and insert into vector store\n",
    "    vectors = embedding_fn.encode_documents(all_chunks)\n",
    "\n",
    "    data = [\n",
    "        {\"id\": i, \"vector\": vectors[i], \"text\": all_chunks[i]} for i in range(len(vectors))\n",
    "    ]\n",
    "\n",
    "    print(\"Data has\", len(data), \"entities, each with fields:\", data[0].keys())\n",
    "    print(\"Vector dim:\", len(data[0][\"vector\"]))\n",
    "\n",
    "    res = client.insert(collection_name=\"demo_collection\", data=data)\n",
    "    print(res)\n",
    "\n",
    "# Example usage\n",
    "csv_file_path = \"./docs/sklearn_stackoverflow.csv\"\n",
    "process_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
